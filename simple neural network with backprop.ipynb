{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # make sure using an updated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To initialize tensor variables in pytorch we need to use the following syntax :\n",
    "\n",
    "## variable_name=torch.tensor(value)\n",
    "\n",
    "\n",
    "#### definition of tensor:\n",
    "tensors is an object that is invariant under change of coordinated and has companents that change in predictable way under change of coordinates.\n",
    "\n",
    "\n",
    "\n",
    "--think tensor as an multidimensional array \n",
    "\n",
    "--they are generalization of vectors,arrays and scalars\n",
    "\n",
    "-scalars are rank 0 tensors\n",
    "\n",
    "-vectors are rank 1 tensors\n",
    "\n",
    "-2d arrays are rank 2 tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x)) # x is a tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing a tensor with multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2272, -0.6555,  0.3379, -0.1619,  0.4210],\n",
      "        [-1.4866,  0.9080, -1.2738, -0.0583, -0.6873],\n",
      "        [-1.3567, -0.3214, -0.0206,  1.5011, -2.0716],\n",
      "        [-0.9233, -0.0331,  0.3061,  2.1714, -0.0334],\n",
      "        [ 1.6504,  0.3805, -0.6850, -0.2687,  0.9572]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple gradient calculation in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1, requires_grad=True) # requires_grad=True tells that the gradient has to be calculated\n",
    "w = torch.tensor(2, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = w * x #computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # backward function calculates the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(w.grad , x.grad ) # returns the value of calculated gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Simple Neural Network with loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit advanced example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(12,5) \n",
    "'''12 is the number of rows and 5 is the number of columns.\n",
    "    more intiutively, 12 is the no. of inputs and 5 is number of features '''\n",
    "\n",
    "\n",
    "\n",
    "y=torch.randn(12,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight Parameter containing:\n",
      "tensor([[ 0.2452,  0.2327,  0.0156,  0.0380, -0.1704]]) bias Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-4.8001])\n"
     ]
    }
   ],
   "source": [
    "nural_net = nn.Linear(5, 1) # defining input layer with 5 input neurons \n",
    "\n",
    "''' 5 is number of input neurons (no. of features of x)\n",
    "    1 is the number of output neurons'''\n",
    "\n",
    "\n",
    "print ('weight',nural_net.weight,'bias',nural_net.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cal= nn.MSELoss() # defining the criteria for loss calculation ( Mean squared error (y'-y)^2)\n",
    "optimizer = torch.optim.Adam(nural_net.parameters(), lr=0.01) #specifying the optimizer (Adam) ,lr =learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = nural_net(x) #forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('loss:', 0.3756197988986969)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_cal(ypred, y) #loss calculation\n",
    "'loss:',loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() # Back propogation (calculating gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight gradient - tensor([[ 0.2703, -0.0694,  0.2483, -0.4878, -0.0540]]) bias gradient- tensor(1.00000e-02 *\n",
      "       [-2.4027])\n"
     ]
    }
   ],
   "source": [
    "print('weight gradient -', nural_net.weight.grad,'bias gradient-',nural_net.bias.grad)\n",
    "\n",
    "#since we have five inputs so five gradients and one output so one bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## repeating the above process several times to check how loss decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss afterEpoch0 0.36479899287223816\n",
      "loss afterEpoch1 0.3554156720638275\n",
      "loss afterEpoch2 0.3474698066711426\n",
      "loss afterEpoch3 0.34096136689186096\n",
      "loss afterEpoch4 0.33589038252830505\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    ep='Epoch'+str(epoch)\n",
    "    ypred = nural_net(x)\n",
    "    loss = loss_cal(ypred, y)\n",
    "    optimizer.step()\n",
    "    print('loss after'+ep, loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see loss is gradually decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Stay tuned for part 2  \n",
    "\n",
    "## In part 2 I will cover an actual model (resnet or something like that)  with real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
